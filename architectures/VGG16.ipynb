{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.autograd as ag\n",
    "import mnist_reader\n",
    "import MNISTtools\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import data_split\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also add data augmentation transforms here\n",
    "train_transform = transforms.Compose([transforms.Resize(224),\n",
    "                                      transforms.ToTensor(), transforms.Lambda(lambda x: torch.cat([x,x,x],0)) ])\n",
    "\n",
    "# transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))   #transforms.ToPILImage(),\n",
    "test_transform = transforms.Compose([ transforms.Resize(224), \n",
    "                                     transforms.ToTensor(), transforms.Lambda(lambda x: torch.cat([x,x,x],0)) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Downloading/Checking for data......')\n",
    "trainset = torchvision.datasets.FashionMNIST(root='data/downloads', train=True,\n",
    "                                        download=True, transform=train_transform)       # download=True for the 1st time\n",
    "testset = torchvision.datasets.FashionMNIST(root='data/downloads', train=False,\n",
    "                                        download=True, transform=test_transform)        # download=True for the 1st time\n",
    "train, validation = data_split.train_valid_split(trainset)    # separates 10% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True, num_workers=2)\n",
    "validloader = torch.utils.data.DataLoader(validation, batch_size=10, shuffle=False, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of batches in training:  5400 ,   Total train data:  27000\n",
      "# of batches in test:  1000 ,   Total test data:  5000\n",
      "image size:  torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print('# of batches in training: ',len(trainloader), ',   Total train data: ',len(trainloader)*5)\n",
    "print('# of batches in test: ',len(testloader), ',   Total test data: ',len(testloader)*5)\n",
    "img, label = train[100]\n",
    "print('image size: ', img.size())\n",
    "# plt.imshow(img[0,:,:])\n",
    "# print(type(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the VGG16 trained on imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = torchvision.models.vgg16_bn(pretrained='imagenet')\n",
    "# print(vgg16.classifier[6].out_features)        # 1000, as it was trained for 1000 classes\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "# REMEMBER: vgg16.features --> convolutional layers, vgg16.classifier --> FC layers\n",
    "#--------------------------------------------------------------------------------------\n",
    "\n",
    "# freeze all parameters in covolutional layers\n",
    "for parameter in vgg16.features.parameters():\n",
    "    parameter.require_grad = False\n",
    "\n",
    "in_ftrs = vgg16.classifier[6].in_features\n",
    "features = list(vgg16.classifier.children())[:-1]       # Removing last layer to add out 10 units layer\n",
    "features.extend([nn.Linear(in_ftrs, 10)])               # adding out layer with 10 units\n",
    "vgg16.classifier = nn.Sequential(*features)             # replacing it with the model with new last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vgg16)  # prints the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16=vgg16.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(vgg16):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    acc_test = 0.0\n",
    "    \n",
    "    vgg16.train(False)\n",
    "    vgg16.eval()    \n",
    "    for i,data in enumerate(testloader):\n",
    "        images, labels = data\n",
    "\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        images = ag.Variable(images, volatile=True)\n",
    "        labels = ag.Variable(labels, volatile=True)\n",
    "\n",
    "        outputs = vgg16(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        acc_test += torch.sum(predicted == labels.data)\n",
    "        del outputs, predicted\n",
    "        torch.cuda.empty_cache()\n",
    "    #     gc.collect()\n",
    "\n",
    "    print(acc_test/len(testset))\n",
    "    # print('Test Accuracy of the model on the 10000 test images: %.4f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0606\n"
     ]
    }
   ],
   "source": [
    "test(vgg16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16.train(True)\n",
    "# vgg16.train()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    51] loss: 1.756\n",
      "[1,   101] loss: 1.287\n",
      "[1,   201] loss: 0.971\n",
      "[1,   500] loss: 0.668\n",
      "[1,   501] loss: 0.000\n",
      "[1,  1000] loss: 0.370\n",
      "[1,  1500] loss: 0.338\n",
      "[1,  2000] loss: 0.320\n",
      "[1,  2500] loss: 0.267\n",
      "[1,  3000] loss: 0.258\n",
      "[1,  3500] loss: 0.254\n",
      "[1,  4000] loss: 0.236\n",
      "[1,  4500] loss: 0.237\n",
      "[1,  5000] loss: 0.225\n",
      "epoch:  0\n",
      "Total time taken in training (secs):  1110.70010591\n",
      "[2,    51] loss: 0.230\n",
      "[2,   101] loss: 0.226\n",
      "[2,   201] loss: 0.204\n",
      "[2,   500] loss: 0.199\n",
      "[2,   501] loss: 0.000\n",
      "[2,  1000] loss: 0.192\n",
      "[2,  1500] loss: 0.189\n",
      "[2,  2000] loss: 0.181\n",
      "[2,  2500] loss: 0.176\n",
      "[2,  3000] loss: 0.192\n",
      "[2,  3500] loss: 0.172\n",
      "[2,  4000] loss: 0.185\n",
      "[2,  4500] loss: 0.179\n",
      "[2,  5000] loss: 0.175\n",
      "epoch:  1\n",
      "Total time taken in training (secs):  2224.13101792\n",
      "[3,    51] loss: 0.147\n",
      "[3,   101] loss: 0.162\n",
      "[3,   201] loss: 0.149\n",
      "[3,   500] loss: 0.133\n",
      "[3,   501] loss: 0.000\n",
      "[3,  1000] loss: 0.151\n",
      "[3,  1500] loss: 0.146\n",
      "[3,  2000] loss: 0.143\n",
      "[3,  2500] loss: 0.135\n",
      "[3,  3000] loss: 0.149\n",
      "[3,  3500] loss: 0.143\n",
      "[3,  4000] loss: 0.132\n",
      "[3,  4500] loss: 0.137\n",
      "[3,  5000] loss: 0.145\n",
      "epoch:  2\n",
      "Total time taken in training (secs):  3343.98050904\n",
      "Total time taken in training (secs):  3343.98196602\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "for epoch in range(3):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):       # 0 is just to start i from 0\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs = ag.Variable(inputs, requires_grad = False)\n",
    "        labels = ag.Variable(labels, requires_grad = False)\n",
    "        \n",
    "        # transformations\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = vgg16(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss[0].data.cpu().numpy()[0]\n",
    "        # print(type(loss[0].data.cpu().numpy()[0]))\n",
    "        if i==50:\n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 50))\n",
    "        if i==100:\n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n",
    "        if i==200:\n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 200))\n",
    "        if i==500:\n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 500))\n",
    "        \n",
    "        if i % 500 == 499:    # print every 500 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 500))\n",
    "            running_loss = 0.0\n",
    "        del inputs, labels, loss, outputs\n",
    "        torch.cuda.empty_cache()\n",
    "    print('epoch: ', epoch)\n",
    "    print('Total time taken in training (secs): ',time.time()-start)\n",
    "print('Total time taken in training (secs): ',time.time()-start)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9162\n"
     ]
    }
   ],
   "source": [
    "# test(vgg16)    # 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9311\n"
     ]
    }
   ],
   "source": [
    "test(vgg16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
